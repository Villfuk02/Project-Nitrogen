\chapter{Analysis}

Now that we have described the game's design, in this chapter, we will explain the approach we took to implement it from a high-level perspective.
We will provide concrete details only for what will be implemented in the playable demo version, but as always, we will make many decisions based on the original vision of our game.

\section{Game Engine}

Game engines provide many important and useful systems for us, so we can focus on implementing the game logic.
For our game, we chose Unity because it offers all the features we need, and the author is already familiar with it.
There are many game engines we could have used, and the high-level decisions presented in this chapter would be still applicable.
However, in some sections we will use nomenclature that is specific to Unity, so we assume the reader is at least familiar with it.
More information is available in the official documentation~\cite{UnityDocs}.

\section{Procedural Generation}\label{sec:analysis-procedural-generation}

As explained in the previous chapter, a lot of the game will be procedurally generated, including the map of a run and each battle along the way.
In the next few sections, we will decide how to generate the worlds for the battles, and in section~\ref{sec:analysis-waves}, we will focus on generating the waves of attackers.

We also want to procedurally generate the map of each run, however the run map will not be a part of the demo version of our game, so we won't implement the map generator yet.
Many of the parameters for the procedurally generated battles will be decided by the map generator.
For example, at the start of each run, the battles should be easy, and they should gradually get more difficult further into the run.
Additionally, some battles will be special in some way.
For example, some battles will be harder, or use a unique terrain type.
We should decide what will be determined by the map generator before the battle generates, and what will be determined only once the battle starts generating.

The map generator will select the terrain type of the world and what attacker types will appear.
These parameters define the theme of the battle.
To control the difficulty, the map generator dictates how difficult should the waves of attackers be, and how much \emph{fuel} is required to finish the level.
This is further explained in section~\ref{sec:analysis-waves}.
The number of attacker path starts and the path lengths also greatly influence the difficulty.
More paths are harder to cover with defenses than a single path.
Shorter paths give the player's defenses less time to deal with the attackers than longer paths.
The map generator will also define the maximum number of path branches, since the paths can split into more.
This is mainly to limit the complexity of the path network in some levels.
There are many more factors which influence the difficulty of the battle, but they are more difficult to quantify, and we believe their influence is not as great.

The map and the map generator will not be a part of the demo, but we still want to let the players play more levels and collect blueprints, until they inevitably lose.
So, we will just create a simple system that will set up the levels with gradually harder attacker waves, shorter paths and different numbers of paths.

The worlds the battles take place on are composed of three somewhat distinct parts~--- paths, terrain and obstacles.
It would make the most sense to generate each part separately, one after another.
We should start with the part that is the most restricted, because each part is additionally restricted by what was generated before it.
For this reason, we will start with paths.
There are a lot of rules the paths should follow, as described in section~\ref{sec:design-paths}.
Additionally, the map generator exactly specifies their number, lengths, and maximum number of branches.
So, we will generate paths first (section~\ref{sec:analysis-path-generation}), then the terrain (\ref{sec:analysis-terrain-generation}), and finally, the obstacles (\ref{sec:analysis-obstacles}).

All the randomized algorithms we will use require a source of randomness.
For reasons described in section~\ref{sec:design-procedural-generation}, we need to choose the right random number generator for our use-case.
This is further explained in section~\ref{sec:analysis-rng}.

\section{Path Generation}\label{sec:analysis-path-generation}

In the previous section, we decided that when generating a world, we will start with the paths.
We also mentioned that we will get the number of path starts, their path lengths and the maximum number of branches as an input from the map generator, because these values heavily influence difficulty.
In section~\ref{sec:design-paths}, we outlined many requirements and suggestions for the paths, in order to make them play well.
Generating a path network with good properties is not an easy task.
To simplify it, we can split the path generation process into three simpler problems:
\begin{enumerate}
    \item Select the Hub position and path starts.
    \item Generate the main branch from each path start.
    \item Refine the paths and make them split and join.
\end{enumerate}
How to accomplish the goal of each of these stages will be described in the following subsections of this section.

Before we continue, we would like to define several terms which we'll use in the rest of this section.
These are illustrated in figure~\ref{fig:path-network}.

As stated in section~\ref{sec:design-world}, the world is formed by a $15\times15$ grid of square \textbf{tiles}.
Each tile shares an edge with up to four \textbf{neighboring tiles}, or \textbf{neighbors}.
The outermost tiles of the world which have less than four neighbors are the \textbf{edge tiles}.
The tile the Hub is on is the \textbf{Hub tile}.
Some tiles can be marked as \textbf{path starts}.

A \textbf{path network} consists of \emph{path segments}.
Each \textbf{path segment} is an oriented straight line from the center of one tile to the center of its neighbor.
We can think of them as the edges in an oriented graph, with tiles being the nodes.
A tile with at least one segment starting or ending at it is a \textbf{path tile}.
A \textbf{path} or a \textbf{branch} is a sequence of consecutive segments.
The \textbf{number of extra branches} of a path network could be defined as the sum of the number of outgoing segments from each tile beyond the first.
For example, the path network in figure~\ref{fig:path-network} has 2 path starts, and because there are two tiles with two outgoing segments each, they make for 2 extra branches.

\begin{center}
    \captionsetup{type=figure}
    \includegraphics[width=0.7\textwidth]{img/Example path network.pdf}
    \caption{A path network in a $7\times7$ tile world.}
    \label{fig:path-network}
\end{center}

If tile $u$ can be reached from tile $t$ by going along $d$ path segments, we say the \textbf{path distance} from $t$ to $u$ is $d$.
Two tiles can have multiple different paths between them, however by requirement RP~\ref{RP:equal-distance}, all of these paths must have the same distance.
When $u$ is not reachable from $t$, they do not have a path distance.
The \textbf{path length} of a start dictates its path distance to the Hub.
For example, the path start on the bottom left of figure~\ref{fig:path-network} has path length 9.

\subsection{Hub Position and Path Starts} \label{sec:analysis-path-starts}

In the first stage of path generation, we need to select the tile the Hub will be on, and all the path starts.
This will be informed by the number of path starts we have to generate and their path lengths.

\head{Hub Position}{hub-pos}
First, we will select the Hub tile.
According to requirement RP\ref{RP:hub-pos}, it \enquote{should not be near the edge of the world, and it should be close to the center in levels with multiple paths}.
There aren't any more requirements, so we will simply select a random tile from tiles that are at most some distance from the center using the euclidean metric.
This distance will be the greatest for levels with one path start and decrease with each additional path start.

\head{Path Start Requirements}{path-start-req}
Now we select the path starts.
According to requirement RP\ref{RP:start-outside}, \enquote{paths start on tiles just outside the playable world, and the first path segment goes from the path start to the nearest tile in the playable world.}
However, other path segments are confined to the actual tiles of the world.
For simplicity, and to avoid edge cases when generating paths, we will pretend, that the paths start at an edge tile of the world, where the first path segment will end.

We will add this segment going over the edge only after the paths are generated.
This segment is uniquely determined anyway, except in the corners of the world, where we'll always select the one that makes the path go straight, as shown in figure~\ref{fig:real-path-starts}.
On the right are the pats as we think of them when generating, and on the left are the actual final paths.
The red circles represent the path starts, and the arrows represent the first segment of each path that only gets added at the end.

\begin{center}
    \captionsetup{type=figure}
    \begin{minipage}{.5\textwidth}
        \centering
        \includegraphics[width=0.95\textwidth]{img/path starts real.pdf}
    \end{minipage}%
    \begin{minipage}{.5\textwidth}
        \centering
        \includegraphics[width=0.95\textwidth]{img/path starts theory.pdf}
    \end{minipage}
    \caption{Real path starts compared to the ones we work with.}
    \label{fig:real-path-starts}
\end{center}

What tiles are valid for a path start with a given path length?
Each start must be at an edge tile, such that a path of the given length can go from it to the Hub.
It is easy to see that the minimum path distance between two tiles is their Manhattan distance.
So, we know that each start cannot be further from the Hub in Manhattan distance that its path length.

We can imagine creating a path backwards from the Hub by appending a segment at every step.
After the first step, the path starts on the neighboring tile of the Hub tile.
Both Manhattan distance and path distance from the tile to the Hub are 1.
After every step, the path distance increases by 1, changing its parity from odd to even or vice versa.
The Manhattan distance to the Hub either increases or decreases by 1, also changing its parity.
Thus, the parity of the path distance and Manhattan distance always match.
This means a path start with an even path length must be a tile with an even Manhattan distance to the Hub, and analogously for odd lengths.

In levels with more paths, we want the path starts to be spread out from each other, in order to cover the world with paths more evenly.
We can choose a minimum distance between the paths starts.
For levels with just one long path, we can also set a minimum distance from the Hub, so it starts further away from it and has more space to zigzag through the world.

\head{Selecting Path Starts}{select-path-starts}
To actually select the starts, we find all edge tiles, and separate them into two sets~--- each for one parity.
Then to select each start, we can use rejection sampling.
This means we take random tiles from the set of with the correct parity until we find one that satisfies all the conditions.
As long as the minimum distances between path starts and from the Hub are small enough, this approach always yields a valid list of path starts.
However, with stricter parameters it is possible that the first few starts invalidate all other start positions.
In that case we can use rejection sampling again~--- trying to randomly select lists of starts, until we get one that's valid.
If the failure rate was great enough, it would be wise to select a different algorithm, but our requirements are not very strict, so rejection sampling works fine.

\subsection{Generating the Main Paths}

From the previous step, we have the Hub position and all the path starts.
Now we want to generate the main paths, which will serve as a template for the next steps.
These paths have to have the correct lengths and follow the requirements, which we set in section~\ref{sec:design-paths}.

We couldn't find many resources on procedurally generated paths.
There is a lot of research on generating road networks, mazes or dungeons.
Theoretically, we could use one of the many algorithms for generating mazes~\cite{MazeWiki}, and modify it to suit our needs.
However, it would be difficult to achieve what we need using an approach that was designed for something else.

We found one algorithm specifically designed for procedurally generating paths, called \emph{path chiseling} by Boris the Brave on his blog~\cite{PathChiseling1,PathChiseling2}.
This algorithm creates random paths on a tile grid by randomly blocking off individual tiles until only one path remains.
This is more promising, however we were unable to find a good way to modify it to generate paths of specific lengths with the properties we want.

Since many of our requirements are more like suggestions, we always want to fulfill them almost the best we can.
This means we can look at the task as an optimization problem: create the \emph{best looking} paths, given the requirements like length, no crossing etc.
Since we want the paths to be randomized, we don't need to find the optimum, we only need a random solution that is good enough.
Given this, we decided to generate the paths using an optimization technique called \emph{simulated annealing}.

\subsection{Simulated Annealing}\label{sec:analysis-simulated-annealing}

Simulated annealing can be used to find an approximation of the global optimum of an optimization problem, much faster than it would take to find the exact global optimum.
A great analysis of this technique can be found in the article \citetitle{SimulatedAnnealing}~\cite{SimulatedAnnealing}.
In this section, we will describe the technique, and in the next section~(\ref{sec:analysis-our-simulated-annealing}), we will use it to generate the paths we want.

The problems simulated annealing can be used for have to be formulated as follows:
\begin{quotation}
    From the set of all states $S$, find a state $s^*$ that minimizes the cost function $f \colon S \to \R$, given a neighbor function $n \colon S \to \mathcal{P}(S)$ which gives the \emph{neighbor states} of each state.
\end{quotation}
For example, to use simulated annealing to solve the \emph{travelling salesman problem}, each state is usually defined as a permutation of the cities to be visited.
The cost function then gives the length of the salesman's path, and the neighbor function gives all the states that can be acquired by swapping two cities in the original state.

The process of simulated annealing is described in pseudocode as algorithm~\ref{alg:simulated-annealing}.
It starts in an initial state $s_0$ and runs for $max\_steps$ steps.
For each step, a temperature $t$ is computed, slowly decreasing from $t_{initial}$ in the first step, to $t_{final}$ at the final step.
In each step, a random neighbor $s'$ of the current state $s$ is selected, and an acceptance probability $p$ is computed, based on the values of $f(s)$, $f(s')$ and the current temperature $t$.
The new state $s'$ is then set as the current state with probability $p$.

This acceptance probability function can be implemented however we see fit, however it should follow these rules:
It always accepts a better new state ($s'$ such that $f(s') < f(s)$), but it can also give a non-zero probability when the new state is worse that the current state ($f(s') > f(s)$).
The probability to accept a worse new state decreases with decreasing temperature.
The acceptance probability of state $t$ cannot be greater than the probability of $u$ when $t$ is worse than $u$ ($f(t) > f(u)$).

\begin{algorithm}[H]
    \caption{Simulated annealing}
    \label{alg:simulated-annealing}
    \begin{algorithmic}[1]
        \State $s \gets s_0$
        \For{$k$ from $0$ to $max\_steps-1$}
        \State $t \gets$ \Call{Lerp}{$t_{initial}$, $t_{final}$, $k/(max\_steps-1)$}
        \State $s' \gets$ random neighbor from $n(s)$
        \State $p \gets$ \Call{AcceptanceProbability}{$f(s)$, $f(s')$, $t$}
        \State with probability $p$: $s \gets s'$
        \EndFor\\
        \Return $s$
        \Statex
    \end{algorithmic}
\end{algorithm}

It is easy to see that if the algorithm never accepted states which are worse than the current state, it would gradually reach a local optimum.
Since it also accepts worse states, it can move away from the local optimum and hopefully end up in a better one.
The probability to accept a worse state gradually decreases with the decreasing temperature.
So at the start, when the temperature is high, the algorithm explores the search space a lot, but as the temperature decreases, it is less and less likely to escape from the local optimum it finds.
Since the exploration prioritizes better states, it is more likely to lead the algorithm to a better optimum than a worse one.

\subsection{Generating Paths using Simulated Annealing}\label{sec:analysis-our-simulated-annealing}

To use simulated annealing to optimize paths, we need to formulate our task as an optimization problem that simulated annealing can solve.
We need to define what is a state, a cost function and a neighbor function.

\head{States}{sa-states}
Each state is a path network composed of one path for each path start.
We will represent each path by a sequence of tiles the path goes through.
Two consecutive tiles in the sequence must be neighbors.
Additionally, each path starts at the given path start, has the correct length, and ends at the Hub tile.
We chose this representation to make it easy to generate neighbor states.
Notice, that we don't check for any intersections and a path can visit one tile multiple times.
This is because the state is going to change only by a small amount at every step.
If we banned intersections, we would lose too much freedom during the simulated annealing, and the final state would always end up close to the initial state.

\head{Neighbor States}{sa-neighbors}
We decided that two states are neighbors when they differ only by one tile.
To generate the set of all neighbors, we have to find all the ways to change one tile in the state to a different tile, such that the result is still a valid state.

For a state to be valid, we require that each path starts with the path start and ends with the Hub tile.
This means that the first and last tile of every path can never change.
For each other tile, there aren't many options on how to change it.
All these options, up to symmetry, are illustrated in figure~\ref{fig:path-tile-swaps}.
The tiles in the sequence are drawn as circles connected by arrows that show their order in the sequence.
The tile we plan to change is drawn as a red circle.
Additionally, we draw the tiles which go before and after it in the sequence.
These are the only tiles that determine the possible changes.

When the tiles form a straight line, no change is possible.
When they form a right angle, one change is possible.
And when the same tile comes before and after, 3 changes are possible.

\begin{center}
    \captionsetup{type=figure}
    \includegraphics[width=0.7\textwidth]{img/SA tile swaps.pdf}
    \caption{All the possible tile changes.}
    \label{fig:path-tile-swaps}
\end{center}

\head{Cost function}{sa-cost-function}
Now we select a cost function that gives a better score to paths that are more desirable.
Since we want the paths to spread out, we can calculate for each tile of the world what we call a \emph{crowding penalty}.
Each time a tile appears in the state, it's crowding penalty increments by 1, and all other tiles get a lower penalty decreasing with euclidean distance.
This way, the tiles that get visited the most times get the highest crowding penalty.
A tile can be substantially crowded even when no path goes through it just because there is a lot of paths around it.

We will denote the crowding penalty that tile $t$ gets from tile $u$ as $c(t,u)$.
The total crowding penalty from tiles in state $s$ for a given tile $t$ is then $c_t(t,s) = \sum_{u \in s} c(t,u)$.

We also add a big crowding penalty to the tiles along the edge of the world, which gradually decreases as we go away from the edge.
This is to push the paths away from the edges, as that is undesirable by requirement RP\ref{RP:undesirable}.
We will denote the crowding penalty that tile $t$ gets from its closeness to the edge as $c_e(t)$.

We define the cost function of a state $s$ as the sum of the crowding penalties of each tile in the state:
\begin{equation*}
    f(s) = \sum_{t \in s} \left(c_e(t) + c_t(t)\right) = \sum_{t \in s} \left(c_e(t) + \sum_{u \in s} c(t,u) \right)
\end{equation*}
This is an obvious choice, because we want each tile to be crowded as little as possible.
So, a state with less crowded tiles has a lower cost, and a state with more crowded tiles has a higher cost.

However, we can just calculate the relative improvement $r_i = f(s) - f(s')$ between the current state $s$ and the new state $s'$ to save on computation.
The relative improvement still gives us enough information to create a good acceptance probability function, but it is simple to compute, because $s$ and $s'$ share most of their tiles.

For $s'$ obtained by changing tile $v$ in $s$ to $w$, we can calculate $r_i$ as
\begin{equation*}
    r_i = c_e(v) - c_e(w)  + 2 c_t(v,s) - 2 c_t(w,s) + 2c(w,v) - 2.
\end{equation*}
We prove this in section~\ref{sec:analysis-proof-improvement}.
This can be computed in $O(1)$ time if we keep the $c_t(t,s)$ of every tile $t$ in the world.
We have to keep all $c_t$ updated when we change the current state to the new state.
This update is simple for each tile $t$:
\begin{equation*}
    c_t(t,s') = c_t(t,s) - c(t,v) + c(t,w).
\end{equation*}

\head{Initial State}{sa-initial-state}
Now, with the problem formulated, we still need to fill in a few details to be able to solve it.
First, we need to produce an initial state.
This is not trivial, because of our constraints on what's considered a valid state.
Namely, every path has to be the correct length.
However, we can easily produce a valid initial state using a random walk from each path start.

The algorithm starts on the path start tile, and adds it to the state as the first path tile of this path.
Then it moves to a random neighbor and appends it to the sequence.
This is repeated until it creates a path of the correct length.
However, we need to ensure that the path ends at the Hub.
To achieve this, we just make the algorithm never select a tile that is further away from the Hub in Manhattan distance than the remaining length of the path.

\head{Acceptance Probability Function}{sa-acceptance-probability-function}
Next, we need to select an acceptance probability function that works well for this problem.
We don't compute the cost of the current state $f(s)$ and the cost of the new state $f(s')$ separately, instead we compute only the relative improvement $r_i = f(s) - f(s')$.
This means that the function will decide on the probability only based on the relative improvement and the temperature.
The function needs to fulfill the requirements outlined in the previous section~\ref{sec:analysis-simulated-annealing}.
The most straight-forward function is simply $r_i - t$.
This function can return values greater than 1 and less than 0, this does not matter, because when testing the probability, these values get treated as 1, respectively 0.

Is this the best function for this problem?
We don't know, but it performed well in our testing, so we kept it.

\head{Intersection Untwisting}{sa-intersections}
However, when we use simulated annealing with these parameters, it still sometimes produces paths that intersect.
This is because it is difficult for the algorithm to fix a loop in the path, as shown on the left in figure~\ref{fig:untwisting-paths}.
It would first have to bring many path tiles closer together, in order to let them cross over each other.
This is the sort of problem simulated annealing is supposed to be able to overcome.
However, we can help it by adding a step that just \emph{untwists} crossings by reversing the section of the path that forms a loop, as shown in the figure.
This still leaves two identical tiles, but now, simulated annealing can drive these apart without any issue.

\begin{center}
    \captionsetup{type=figure}
    \begin{tikzpicture}
        \draw[step=1.0,black,thin] (0,0) grid (4,4);
        \draw[step=1.0,black,thin] (6,0) grid (10,4);
        \begin{scope}[blue,very thick,decoration={
                        markings,
                        mark=between positions 0.25cm and -0.05cm step 0.5cm with {\arrow{>}};
                    }]
            \draw[postaction={decorate},shift={(0.5,0.5)}] (-1,1)--(3,1);
            \draw[white,line width=4pt,shift={(0.5,0.5)}] (1,0.6)--(1,1.4);
            \draw[postaction={decorate},shift={(0.5,0.5)}] (3,1)--(3,3)--(1,3)--(1,-1);
            \draw[postaction={decorate},shift={(0.5,0.5)}] (5,1)--(6.95,1.05);
            \draw[postaction={decorate},shift={(0.5,0.5)}] (6.95,1.05)--(7,3);
            \draw[postaction={decorate},shift={(0.5,0.5)}] (7,3)--(9,3)--(9,1);
            \draw[postaction={decorate},shift={(0.5,0.5)}] (9,1)--(7.05,0.95);
            \draw[postaction={decorate},shift={(0.5,0.5)}] (7.05,0.95)--(7,-1);
        \end{scope}
        \draw[->,very thick,shift={(0.5,0.5)}] (4,1.5) -- (5,1.5);
    \end{tikzpicture}
    \caption{Untwisting a self-intersecting path.}
    \label{fig:untwisting-paths}
\end{center}

This modification of the state is valid, because the length of the path doesn't change.
However, we cannot untwist crossings between two different paths, because that could change their lengths.
This means that we should take special care to not produce an initial state where two different paths cross.
We can achieve this by calculating crowding penalties while creating the initial state.
Then, when the random walk algorithm selects a random neighbor to move to, we make it prefer the neighbors with a lower crowding penalty.
Because we don't mind self-intersections, we don't add the crowding penalties from the nodes of the path the algorithm is currently creating.
We add them only when the path is complete.

Still, the algorithm sometimes fails in creating a valid path network.
In case no valid network is generated, we can restart the path generation algorithm, including picking new starting positions.

In figure~\ref{fig:simulated-annealing}, we can see how the paths evolve over time as the temperature decreases.
\begin{center}
    \captionsetup{type=figure}
    \begin{minipage}{.5\textwidth}
        \centering
        \includegraphics[width=0.95\linewidth]{img/SA initial state.pdf}
        \subcaption{Initial state ($t_{initial} = 2.5$)}
    \end{minipage}%
    \begin{minipage}{.5\textwidth}
        \centering
        \includegraphics[width=0.95\linewidth]{img/SA temp 2.pdf}
        \subcaption{$t = 2$}
    \end{minipage}\\
    \begin{minipage}{.5\textwidth}
        \centering
        \includegraphics[width=0.95\linewidth]{img/SA temp 1.5.pdf}
        \subcaption{$t = 1.5$}
    \end{minipage}%
    \begin{minipage}{.5\textwidth}
        \centering
        \includegraphics[width=0.95\linewidth]{img/SA final.pdf}
        \subcaption{Result ($t_{final} = 1$)}
    \end{minipage}
    \caption{Evolution of paths during simulated annealing.}
    \label{fig:simulated-annealing}
\end{center}

\subsection{Simplifying the Relative Improvement Calculation}\label{sec:analysis-proof-improvement}

In paragraph~\nameref{head:sa-cost-function} of the previous section, we defined the cost function we will use and its components:
The cost function for state $s$ is
\begin{equation*}
    f(s) = \sum_{t \in s} \left(c_e(t) + \sum_{u \in s} c(t,u) \right).
\end{equation*}
Where $c(t,u)$ is the crowding penalty that tile $t$ gets from its distance to tile $u$, and $c_e(t)$ is the crowding penalty tile $t$ gets from its distance to the edge of the world.
The total crowding penalty from tiles in state $s$ for a given tile $t$ is then $c_t(t,s) = \sum_{u \in s} c(t,u)$.
We also stated that we will only calculate the relative improvement $r_i = f(s) - f(s')$ between the current state $s$ and the new state $s'$.

In this section, we show that the relative improvement $r_i = f(s) - f(s')$ for $s'$ obtained by changing tile $v$ in $s$ to $w$ can be calculated as
\begin{equation*}
    r_i = c_e(v) - c_e(w)  + 2 c_t(v,s) - 2 c_t(w,s) + 2c(w,v) - 2.
\end{equation*}

We start by substituting the definition for the cost function $f$.
\begin{align*}
    r_i & = f(s) - f(s')                                                                                                                 \\
        & = \sum_{t \in s} \left(c_e(t) + \sum_{u \in s} c(t,u) \right) - \sum_{t \in s'} \left(c_e(t) + \sum_{u \in s'} c(t,u) \right). \\
\end{align*}
Now we separate $v$ from $s$ and $w$ from $s'$.
\begin{align*}
     & = \sum_{t \in s} \left(c_e(t) + c(t,v) + \sum_{u \in s - v} c(t,u)\right) - \sum_{t \in s'} \left(c_e(t) + c(t,w) + \sum_{u \in s' - w} c(t,u) \right) \\
     & = \left(c_e(v) + c(v,v) + \sum_{u \in s - v} c(v,u)\right) + \sum_{t \in s - v} \left(c_e(t) + c(t,v) + \sum_{u \in s - v} c(t,u)\right)               \\
     & \ - \left(c_e(w) + c(w,w) + \sum_{u \in s' - w} c(w,u) + \sum_{t \in s' - w} \left(c_e(t) + c(t,w) + \sum_{u \in s' - w} c(t,u) \right) \right).       \\
    \intertext{We use that $s - v = s' - w$, and we name $q$ the set of tiles both states have in common.}
     & = c_e(v) + c(v,v) + \sum_{u \in q} c(v,u) + \sum_{t \in q} \left(c_e(t) + c(t,v) + \sum_{u \in q} c(t,u)\right)                                        \\
     & \ - \left(c_e(w) + c(w,w) + \sum_{u \in q} c(w,u) + \sum_{t \in q} \left(c_e(t) + c(t,w) + \sum_{u \in q} c(t,u) \right)\right)                        \\
     & = c_e(v) + c(v,v) + \sum_{u \in q} c(v,u) + \sum_{t \in q} c_e(t) + \sum_{t \in q} c(t,v) + \sum_{t \in q} \sum_{u \in q} c(t,u)                       \\
     & \ - \left(c_e(w) + c(w,w) + \sum_{u \in q} c(w,u) + \sum_{t \in q} c_e(t) + \sum_{t \in q} c(t,w) + \sum_{t \in q} \sum_{u \in q} c(t,u)\right)        \\
     & = c_e(v) + c(v,v) + \sum_{u \in q} c(v,u) +  \sum_{t \in q} c(t,v)                                                                                     \\
     & \ - \left(c_e(w) + c(w,w) + \sum_{u \in q} c(w,u) + \sum_{t \in q} c(t,w) \right).                                                                     \\
    \intertext{The function $c$ is symmetric, because it depends only on the distance between the tiles, which is symmetric, so we get:}
     & = c_e(v) + c(v,v) + 2 \sum_{t \in q} c(v,t) - \left(c_e(w) + c(w,w) + 2 \sum_{t \in q} c(w,t) \right).                                                 \\
    \intertext{The crowding a tile inflicts to itself is 1, so $c(v,v) = c(w,w)$.}
     & = c_e(v) - c_e(w)  + 2 \sum_{t \in q} c(v,t) - 2 \sum_{t \in q} c(w,t) .                                                                               \\
    \intertext{We can add the terms $2c(v,v) - 2c(v,v) + 2c(w,v) - 2c(w,v)$ because they sum to zero:}
     & = c_e(v) - c_e(w)  + 2 \sum_{t \in q} c(v,t) - 2 \sum_{t \in q} c(w,t)                                                                                 \\
     & \ + 2c(v,v) - 2c(v,v) + 2c(w,v) - 2c(w,v),                                                                                                             \\
    \intertext{and we collect the sums to sum over the elements of $s$:}
     & = c_e(v) - c_e(w)  + 2 \sum_{t \in s} c(v,t) - 2 \sum_{t \in s} c(w,t) - 2c(v,v) + 2c(w,v)                                                             \\
     & = c_e(v) - c_e(w)  + 2 c_t(v,s) - 2 c_t(w,s) - 2c(v,v) + 2c(w,v)                                                                                       \\
     & = c_e(v) - c_e(w)  + 2 c_t(v,s) - 2 c_t(w,s) + 2c(w,v) - 2 .                                                                                           \\
\end{align*}
$\hfill\square$

So we see that the equality holds, letting us compute the relative improvement more efficiently.

\subsection{Final Paths}

Now that we have generated the main paths, we just have to generate the side branches.
The world generation steps that come after have to make sure to not block the paths we have generated.
However, we don't want to constrain them with the whole path network.
Since we don't have requirements on the minimum side branch count or their lengths, it is enough to ensure the paths we generated in the previous step get preserved.
We can generate the rest of the world first, and only then make extra paths where they fit.
We don't want the branching to feel the same in every level.
This lets us use the randomness of the world generation instead of needing to introduce more in this stage.

Due to this decision, this step will start with an already generated terrain and obstacles, as described in sections~\ref{sec:analysis-terrain-generation} and~\ref{sec:analysis-obstacles}.
These steps respect the original paths, but they will cause other tiles or edges between them to be blocked, as shown in figure~\ref{fig:paths-world}.
Here, we can see the original paths on the left.
On the right, we can see tiles blocked by obstacles as gray squares with black edges.
Additionally, some edges between tiles are also blocked, usually because the two tiles are at different height levels, separated by a cliff.
These are the remaining black lines.

\begin{center}
    \captionsetup{type=figure}
    \begin{minipage}{.5\textwidth}
        \centering
        \includegraphics[width=0.95\textwidth]{img/Generated Paths.pdf}
    \end{minipage}%
    \begin{minipage}{.5\textwidth}
        \centering
        \includegraphics[width=0.95\textwidth]{img/Paths and world.pdf}
    \end{minipage}
    \caption{Blocked edges and tiles after generating the terrain and obstacles.}
    \label{fig:paths-world}
\end{center}

Now, how do we actually generate the path network?
There are so many blocked edges that we want to add all the valid branches we find, up to the maximum number of branches decided by the map generator (see section~\ref{sec:analysis-procedural-generation}).
To do this, we will use depth first search, but we will add a few heuristics to produce better paths.
To decide on these heuristics, we will set a few more requirements:
We still want the paths to be spread out, but we would prefer the paths to go straight if possible.

However, we would also like to somehow capture the shape of the paths that were optimized during the previous stage.
We could simply make the first path from each start be identical to the original path.
We would like multiple paths to sometimes join together, which we cannot do without changing them.
To achieve this, we add a rule for every tile with a path: if an original path also went through it, its path distance must be the same as the original path distance.
This way, the path segments of any new path will be distributed similarly to the original path, since they have to cross at every choke point.
This is illustrated in figure~\ref{fig:respect-originals}.
On the left are the original paths, and on the right are randomly generated paths which respect the rule.
The tiles where the random paths would intersect the original paths are marked with a blue circle.

\begin{center}
    \captionsetup{type=figure}
    \begin{minipage}{.5\textwidth}
        \centering
        \includegraphics[width=0.95\textwidth]{img/Paths and world.pdf}
    \end{minipage}%
    \begin{minipage}{.5\textwidth}
        \centering
        \includegraphics[width=0.95\textwidth]{img/Rnadom but respecting the originals.pdf}
    \end{minipage}
    \caption{Randomly generated paths which respect the original path distances.}
    \label{fig:respect-originals}
\end{center}

We need to make sure the paths we produce are the correct length and respect the required original path distances.
We can save a lot of time by precomputing the minimum distance each tile can have.
This way the algorithm can avoid tiles from which it's impossible to finish a path of the correct length.
For this, we can do a breadth first search from the Hub tile, and we restrict the original path tiles to only \enquote{be found} at the right time and not sooner.
The result can be seen in figure~\ref{fig:path-distances}.
We will call these distances the \emph{minimum distances}.

\begin{center}
    \captionsetup{type=figure}
    \includegraphics[width=0.5\textwidth]{img/Path Distances.pdf}
    \caption{Calculated minimum distances.}
    \label{fig:path-distances}
\end{center}

Now we finally run the depth first search, one path by one.
The algorithm keeps a stack of \emph{path prototypes}.
These are paths, which start at the start tile, but have not reached the Hub yet.
At the start, the stack contains only the path prototype with only the start position as its only element.
At every step, the algorithm pops the last prototype from the stack, finds all valid one-step continuations of the current paths, and adds those to the stack.

Valid continuations are the neighbors of the last tile of the current path prototype that aren't blocked.
Additionally, they have to have a minimum distance that is less than or equal to the remaining length of this path prototype.
The valid continuations are ordered such that the best option will be put onto the stack last, so it gets popped in the next step.
The best option is always the one that goes straight, and the rest is ordered by the same crowding penalty as in paragraph~\nameref{head:sa-cost-function} of section~\ref{sec:analysis-our-simulated-annealing}.

Once the algorithm reaches the Hub or an already existing path, it checks whether it is valid to finish the current path.
First, it must have the correct remaining length to produce a valid path.
When it connects to the Hub, the remaining length must be 0, and for connecting to an existing path, the remaining length must match the path distance of that tile.
Additionally, as per requirement RP\ref{RP:branch}: \enquote{every branch must go through at least one tile that is not adjacent to any already existing path}.

If this check fails, the algorithm does not mark this branch, it pops the last item from the stack and continues from there.
If the check succeeds, it marks the new path section and updates the crowding penalties to take the new path section into account.
Then it continues by making another branch.

However, the last path prototype on the stack will share most of its tiles with the branch we just found.
We want the branches be separated from each other as much as possible.
To minimize the shared section, we take the path prototype from the opposite end of the stack.
So, in reality, we won't use a stack, but a double ended queue.
The entire search is described in pseudocode as algorithm~\ref{alg:path-finalizing}.

\begin{algorithm}[H]
    \caption{Finalizing paths}
    \label{alg:path-finalizing}
    \begin{algorithmic}[1]
        \ForEach{path start $start$}
        \State $stack$.\Call{PushLast}{path prototype containing only $start$}
        \State $success \gets$ \mono{false}
        \Statex
        \While{$stack$ is not empty}
        \If{$success$}
        \State $p \gets stack$.\Call{PopFirst}{}
        \Else
        \State $p \gets stack$.\Call{PopLast}{}
        \EndIf
        \Statex
        \If{last tile in $p$ contains a path or the Hub}
        \State $success \gets$ \Call{TryFinishPath}{$p$}
        \Else
        \State $success \gets$ \mono{false}
        \ForEach{tile $c$ from \Call{GetValidContinuations}{$p$}}
        \State $stack$.\Call{PushLast}{$p$ extended by $c$}
        \EndFor
        \EndIf
        \EndWhile
        \EndFor
        \Statex
    \end{algorithmic}
\end{algorithm}

With this ordering of valid continuations, the algorithm usually reaches the Hub too soon, and then it has to backtrack many times before producing a path that is the right length.
To fix this, we prioritize above all the tiles with minimum distance exactly equal to the remaining length.
The results of the algorithm are displayed on the right in figure~\ref{fig:final-paths}, compared to the initially generated paths on the left.
Segments that have changed are highlighted in red.

\begin{center}
    \captionsetup{type=figure}
    \begin{minipage}{.5\textwidth}
        \centering
        \includegraphics[width=0.95\textwidth]{img/Paths and world.pdf}
    \end{minipage}%
    \begin{minipage}{.5\textwidth}
        \centering
        \includegraphics[width=0.95\textwidth]{img/Final Paths.pdf}
    \end{minipage}
    \caption{Final paths compared to the originally generated paths.}
    \label{fig:final-paths}
\end{center}

\section{Terrain Generation}\label{sec:analysis-terrain-generation}

There are many techniques we could use for generating the terrain.
However, we have pretty strict requirements for the terrain generation.
We need to make sure the paths we have generated in the previous step are not blocked by terrain features like cliffs.
We also want the algorithm to be able to generate different-looking terrain types.

This led us to a variant of a procedural generation algorithm called \emph{model synthesis}, originally developed by \Citeauthor{ModelSynthesis}~\cite{ModelSynthesis}.
The discrete version of this algorithm is better known by the name \emph{wave function collapse} (or~WFC in short), popularized by \Citeauthor{WFC} on GitHub~\cite{WFC}.
Model synthesis is more general and focuses more on 3D models, whereas WFC applies the same concepts to generating 2D pixel art and tile maps.
Since the name \enquote{wave function collapse} is more popular, we will use it in the rest of this thesis, even though it's not the name of the algorithm that came first.

We chose WFC, because it can generate randomized terrain, whilst fully respecting the initial constraints we give it.
To see how this works, we will explain the algorithm first.

\subsection{Wave Function Collapse}

The original intent behind the algorithm is to replicate the structure of an example on a larger scale, making sure that the output is locally similar to the input, as shown in figure~\ref{fig:wfc-example}.
We will limit our examples to 2-dimensional grids of tiles, however this algorithm works in more dimensions.

\begin{center}
    \captionsetup{type=figure}
    \includegraphics[width=0.5\textwidth]{img/WFC Example.pdf}
    \caption{Example input and output of the wave function collapse algorithm.}
    \label{fig:wfc-example}
\end{center}

The first step of the algorithm is to extract from the input which features can appear next to each other.
The algorithm creates a set of \emph{modules}\footnote{This is a naming convention used in an article by \Citeauthor{WFCMarian}~\cite{WFCMarian}.}, which are the building blocks the output will be built from.
Each module comes with a set of constraints on its neighbors.
The main portion of the algorithm then builds the output from these modules, such that all the constraints are satisfied, and each module appears in the output with a similar frequency to the input.
However, we will create the modules for our generator by hand, including their constraints, in order to have greater control over the generated result.
In figure~\ref{fig:wfc-modules}, we can see a set of 7 modules and the resulting output, given only the constraint that the edges of directly adjacent modules must match.

\begin{center}
    \captionsetup{type=figure}
    \includegraphics[width=0.5\textwidth]{img/WFC modules.pdf}
    \caption{Example output of WFC, using the modules on the left and only the constraint that their edges must match.}
    \label{fig:wfc-modules}
\end{center}

We call each spot in the output where a module is supposed to be a \emph{slot}.
Each slot keeps track of all the modules that can be placed in it.
At the start of the main part of the algorithm, all slots are initialized with all the modules.
Figure~\ref{fig:wfc-initial} shows a visualization of this state.
Then the algorithm repeats two actions: collapse a slot, propagate constraints.
To collapse a slot, the algorithm removes all possible modules from the slot except for one, chosen at random.

Then it has to propagate constraints, which means that it removes from each slot all the modules which can no longer be placed there.
For example, in figure~\ref{fig:wfc-step-1} we see that a slot has collapsed to a module which has a line on each edge.
Thus, the algorithm removes from the neighboring slots (marked in red) all modules which don't have a line at the corresponding edge.
After propagating constraints, the algorithm collapses another slot and so on.

\begin{center}
    \captionsetup{type=figure}
    \begin{minipage}{.31\textwidth}
        \centering
        \includegraphics[width=0.95\linewidth]{img/WFC initial state.pdf}
        \subcaption{Initial state} \label{fig:wfc-initial}
    \end{minipage}%
    \begin{minipage}{.31\textwidth}
        \centering
        \includegraphics[width=0.95\linewidth]{img/WFC step 1.pdf}
        \subcaption{First step} \label{fig:wfc-step-1}
    \end{minipage}%
    \begin{minipage}{.31\textwidth}
        \centering
        \includegraphics[width=0.95\linewidth]{img/WFC step 2.pdf}
        \subcaption{Second step} \label{fig:wfc-step-2}
    \end{minipage}
    \caption{Two steps of wave function collapse.}
    \label{fig:wfc-steps}
\end{center}

In figure~\ref{fig:wfc-step-2}, we can see an interesting situation after collapsing a second slot.
The slot between the collapsed slots can still contain two possible modules, however both of them have a line at the top and bottom edges.
This means that the algorithm also has to propagate to the neighbors of this tile that they have to have lines at the corresponding edges.
A change in one slot can affect slots even very far away from it.

This process repeats until all slots are collapsed, at which point we have successfully generated the output.
This process is summarized as algorithm~\ref{alg:wfc}.
We left out one detail: which element does \textsc{Pop} select?
This does not matter for the overall function of the algorithm, and it will be further discussed in section~\ref{sec:analysis-our-wfc}.
We will call this algorithm WFC, even though it differs from both WFC by Gumin and Merrell's model synthesis.
The only notable difference is that we skip the feature extraction step, and the algorithm takes as input the modules directly.

\begin{algorithm}[H]
    \caption{A na\"{i}ve version of wave function collapse}
    \label{alg:wfc}
    \begin{algorithmic}[1]
        \ForEach{slot $s$ in output} \Comment{Initialize all slots.}
        \State $s.modules \gets all\_modules$
        \EndFor
        \Statex
        \State $uncollapsed \gets$ all slots
        \While{$uncollapsed$ is not empty}
        \State $s \gets uncollapsed$.\Call{Pop}{} \Comment{Collapse a slot.}
        \State $s.modules \gets \{$random module from $s.modules\}$
        \Statex
        \State $to\_update \gets$ neighbors of $s$ \Comment{Propagate constraints.}
        \While{$to\_update$ is not empty}
        \State $u \gets to\_update$.\Call{Pop}{}
        \Statex
        \State $changed \gets$ \mono{false}
        \ForEach{module $m$ in $u.modules$} \Comment{Remove invalid modules.}
        \If{not \Call{IsValid}{$m$}}
        \State $u.modules \gets u.modules - m$
        \State $changed \gets$ \mono{true}
        \EndIf
        \EndFor
        \Statex
        \If{$changed$} \Comment{If $u$ changed, enqueue its neighbors.}
        \State $to\_update \gets to\_update\,\cup$ neighbors of $u$
        \EndIf
        \Statex
        \EndWhile
        \EndWhile
        \Statex
    \end{algorithmic}
\end{algorithm}

However, it is possible for the algorithm to create a slot with no valid module.
In that case, it is no longer possible to create a valid output.
We call this situation a \emph{conflict}.
An example can be seen in figure~\ref{fig:wfc-backtracking}.
If we look at WFC as a \emph{constraint satisfaction problem} solver, we can see that the constraint propagation only ensures \emph{arc-consistency}, which is not enough to rule out conflicts.
This is concisely explained in the Wikipedia article on local consistency~\cite{LocalConsistencyWiki}.

We called algorithm~\ref{alg:wfc} na\"{i}ve, because it is unable to deal with any conflicts.
What can we do to always produce a result, even when a conflict happens?
One option is to simply restart the algorithm.
For sufficiently small outputs, conflicts should be rare enough, only needing a few restarts.

Another option is to use backtracking.
Whenever the algorithm runs into a contradiction after collapsing a slot, it returns to the state before collapsing.
Additionally, it removes the module the slot collapsed to from its valid options, because it now knows it causes to a conflict.
The state after backtracking is illustrated in fig~\ref{fig:wfc-after-backtracking}.
This way, the algorithm can continue generating without getting rid of all its progress.

\begin{center}
    \captionsetup{type=figure}
    \begin{minipage}{.31\textwidth}
        \centering
        \includegraphics[width=0.95\linewidth]{img/WFC backtracking before.pdf}
        \subcaption{Before collapsing} \label{fig:wfc-before-backtracking}
    \end{minipage}%
    \begin{minipage}{.31\textwidth}
        \centering
        \includegraphics[width=0.95\linewidth]{img/WFC backtracking dead end.pdf}
        \subcaption{After collapsing} \label{fig:wfc-dead-end}
    \end{minipage}%
    \begin{minipage}{.31\textwidth}
        \centering
        \includegraphics[width=0.95\linewidth]{img/WFC backtracking after.pdf}
        \subcaption{After backtracking} \label{fig:wfc-after-backtracking}
    \end{minipage}
    \caption{Conflicts and backtracking in WFC. The red cross marks a slot with no valid modules.}
    \label{fig:wfc-backtracking}
\end{center}

\subsection{Advantages and Disadvantages of WFC}

The main advantage of WFC is that it offers a lot of control over the generated world.
That's ultimately why we chose to use it.
We always know what features can appear in the world, because we explicitly select them as building blocks of the terrain.
We can also freely constrain the world that we are generating.
For example, we can force the generator to not block the paths we've generated in the previous stage, and we can force the tile with the Hub to be flat.
We also force a random tile to be at the lowest height level and another to be at the highest.

However, WFC has some disadvantages when used as a terrain generator.
First, it can be very slow.
The time it takes algorithm~\ref{alg:wfc} to run scales linearly with the number of slots, which is not bad.
We show this in section~\ref{sec:analysis-wfc-time-complexity}.
However, when we take contradictions into account, it gets worse.
Merrell shows in section 3.3.5 of their thesis that deciding whether an incomplete output is consistent, i.e., it can be completed without running into contradictions, is an NP-complete problem.
This necessarily means that WFC isn't very fast in the worst case.

The real problem is that the algorithm usually does run into contradictions, and the larger the generation task, the more likely it is to run into a contradiction.
This is especially bad for online generation of infinite worlds, because we can't simply restart and generate a new world after the player has already seen a part of it.
Backtracking also doesn't solve this issue, because the algorithm can collapse a slot in a way that is guaranteed to cause a contradiction, and then do arbitrarily many more steps before finally running into it.
Of course, there are ways to circumvent this issue, namely by making the individual generation tasks smaller.
In section 3.3.6 of their thesis, Merrell describes a technique called \emph{modifying in parts} based on this approach.
Luckily, this is not a problem for us, because our world is very small.

Another potential problem with WFC is that the individual slots or modules can be very apparent and repetitive.
This can be solved by procedurally generating the resulting geometry the player sees, only based on the modules chosen by WFC.
Another way to make the slots less apparent is to make the slots irregular.
Both of these techniques are used by \emph{Townscaper}~\cite{Townscaper}, a game by Oskar St\r{a}lberg.
This also isn't a problem for us: we don't mind that the tiles will be apparent, since the gameplay of our game is centered around them anyway

Also, WFC only uses local constraints, so it provides no control over the more global features of the output.
On a large scale, the results are very homogenous.
For larger outputs, WFC should only be used to generate the local features, guided by large-scale features generated by some other algorithm.
Our game world is also too small for this to matter.

\subsection{Using WFC for Terrain Generation}\label{sec:analysis-our-wfc}

Even though we want to generate a 3D terrain, our output will consist of a 2D grid of slots.
We want the tiles of the generated world to be at different heights, however, we don't want any tiles to generate above other tiles.
Ultimately, this is a 2D generation task, with the addition that modules can appear at different height levels.

At first, it might seem sensible to have one slot per world tile.
However, each tile on its own will be mostly a flat square.
The interesting terrain features will appear on the boundaries between the tiles.
For example, two tiles at different height levels next to each other will have a cliff separating them.
If we wanted to incorporate the cliff into the tile module, which tile does it belong to?
What about the features where the corners of four tiles meet?
We offset the slots in a way shown in figure~\ref{fig:tiles-and-slots}, such that each slot is responsible for four quarter-tiles of the world.
Tiles are drawn in black, slots in red.
This way, the modules dictate how can the adjacent tiles connect to each other.

\begin{center}
    \captionsetup{type=figure}
    \begin{tikzpicture}
        \draw[step=1.0,thick,red] (0,0) grid (4,4);
        \draw[step=1.0,black,thick,shift={(0.5,0.5)}] (0,0) grid (3,3);
    \end{tikzpicture}
    \caption{The slots for generating a $3\times3$ tile world.}
    \label{fig:tiles-and-slots}
\end{center}

One example of such module is shown in figure~\ref{fig:wfc-module}.
Each module constrains the 8 adjacent slots.
An edge type is specified for each edge, and modules which share an edge must have the same edge type.
For each corner of the module, several tile constraints are specified.
The modules that share a tile must agree on the tile's properties: its height, slant direction (if any) and surface type.
Terrain types can have multiple surface types, each with a different set of modules and a few modules that allow to transition between them.
For example, a \emph{shore} module could have \emph{ground} tiles on one side and \emph{water} tiles on the other.
Some surface types block paths and buildings and some edge types block paths.
What modules are available for the generator will be determined by the terrain type that was chosen for this world.

\begin{center}
    \captionsetup{type=figure}
    \begin{minipage}{.5\textwidth}
        \centering
        \includegraphics[width=0.95\textwidth]{img/Module model.png}
    \end{minipage}%
    \begin{minipage}{.5\textwidth}
        \centering
        \includegraphics[width=0.95\textwidth]{img/Module constraints.pdf}
    \end{minipage}
    \caption{An example module and its constraints.}
    \label{fig:wfc-module}
\end{center}

In figure~\ref{fig:wfc-modules}, we show 7 modules as an input.
However, when designing them, it would make more sense to think of them as 3 different modules that can each be rotated.
Thus, the modules we use will also have an option to select the allowed reflection and rotations.
Then, before generating the terrain, we will automatically generate all variants of each module.
Each module can also be placed at different height levels, which is handled similarly.
For example, the module shown in figure~\ref{fig:wfc-module} will effectively become 24 different modules in a terrain type with 4 height levels (0, 1, 2, 3), because it has 8 different reflections and rotations, and it can appear at 3 different height levels (0--1, 1--2, 2--3).

For each module, we also specify a weight.
This dictates how likely it is to be selected when collapsing a slot, compared to other modules.
For example, when we collapse a slot that only has two valid modules, with weights 1 and 4, then the first module will be selected with a 20\,\% probability.

We have decided to implement backtracking to solve contradictions.
If the algorithm only ever has to backtrack once before collapsing another slot, we say that it needs backtracking depth 1.
However, it is possible that the algorithm collapses a slot, finds a contradiction, and after backtracking, removes the only remaining module in the slot that was collapsed.
Thus, it creates another contradiction, which causes it to backtrack deeper.

We ran some quick tests with the set of modules which is going to be used to generate terrain in the demo version.
The results are shown in table~\ref{tab:wfc-backtracking}.
For each test, we tried generating 2000 random worlds, each with three path starts with lengths 24, 28 and 33, making them pretty constrained.

\begin{table}[H]
    \centering
    \begin{tabular}{lrrD{.}{.}{-1}r}
        \toprule
        \textbf{Maximum}            &                          &                              & \mc{}                                &                             \\
        \textbf{backtracking depth} & \halfrow{\textbf{Fails}} & \halfrow{\textbf{Successes}} & \mc{\halfrow{\textbf{Success rate}}} & \halfrow{\textbf{Time (s)}} \\
        \midrule
        0                           & 2000                     & 0                            & 100.00\,\%                           & 644                         \\
        1                           & 786                      & 1214                         & 60.70\,\%                            & 740                         \\
        2                           & 783                      & 1217                         & 60.85\,\%                            & 797                         \\
        10                          & 783                      & 1217                         & 60.85\,\%                            & 819                         \\
        \bottomrule
    \end{tabular}
    \caption{Success rate of terrain generation based on maximum backtracking depth. }
    \label{tab:wfc-backtracking}
\end{table}

No world was able to generate without running into a contradiction, i.e., with a backtracking depth 0.
60.7\,\% of the worlds only ever needed backtracking depth of 1 to successfully generate.
Greater backtracking depth doesn't seem to help very much.
Instead, it makes the generator spend more time trying to save worlds which are still going to fail.
We decided to allow for backtracking depth 1 and otherwise just restart the generation to try again.

We also need to decide which slot to collapse at each step of the algorithm.
Merrell uses in their thesis a scan line order, collapsing slots in the lexicographic order of their coordinates.
Gumin in their implementation always collapses a slot with the lowest \emph{Shannon entropy}.
This causes the generation to collapse slots outwards form the slot that was collapsed first.
From our testing, the results tend to look unnatural, often creating regions at the same height, or repeating patterns.

Both approaches grow the collapsed portion of the world from one initial slot, similar to growing a single crystal solid from one seed crystal.
To make the results more natural, we chose to select the slot to collapse at random.
This leads to the generator first collapsing slots in various parts of the world to different configurations.
Then it has to somehow connect these to make the world follow the rules we set.
This leads to much more diverse results, however, the success rate becomes very low, leading to slower generation.

As a compromise, we tried to weight the slots by $1/$entropy, making it more likely to select more constrained slots, but still collapsing unconstrained slots once in a while.
This leads to results similar to the ones with uniform randomness, but it increases the success rate.
However, this results in the algorithm being even slower, probably because calculating the entropy of a slot is not trivial.

In the end, we chose to weight the slots by the number of invalid slots\,$+\,1$.
This is an approximation of entropy that is trivial to compute, but performs in our tests almost identical.
The $+1$ at the end is important to make all weights nonzero.

In table~\ref{tab:wfc-collapsing} are the results of the tests we ran.
For each method, we generated worlds until we successfully generated 1000 of them.
This is to compare the average time it takes to successfully generate a world, which is a more useful metric for us.

\begin{table}[H]
    \centering
    \begin{tabular}{lrrD{.}{.}{-1}r}
        \toprule
        \textbf{Which slot}         &                          &                              & \mc{}                                &                             \\
        \textbf{to collapse?}       & \halfrow{\textbf{Fails}} & \halfrow{\textbf{Successes}} & \mc{\halfrow{\textbf{Success rate}}} & \halfrow{\textbf{Time (s)}} \\
        \midrule
        minimum entropy             & 213                      & 1000                         & 82.44\,\%                            & 492                         \\
        uniformly random            & 823                      & 1000                         & 54.85\,\%                            & 691                         \\
        weighted by $1/$entropy     & 672                      & 1000                         & 59.81\,\%                            & 728                         \\
        weighted by invalid modules & 676                      & 1000                         & 59.67\,\%                            & 656                         \\
        \bottomrule
    \end{tabular}
    \caption{Success rate of terrain generation based on how the algorithm decides which slot to collapse next. }
    \label{tab:wfc-collapsing}
\end{table}

\subsection{Time Complexity of Na\"{i}ve WFC}\label{sec:analysis-wfc-time-complexity}

In this section, we will show that algorithm~\ref{alg:wfc} runs in amortized $O(k^3 \cdot n)$ time, where $k$ is the number of modules, and $n$ is the number of slots.
We will assume that the sets $uncollapsed$, $to\_update$ and the $modules$ of each slot have amortized $O(1)$ queries, additions and removals, including \textsc{Pop}.
Another assumption we make is that \textsc{IsValid} runs in $O(k)$ time, because each slot has $O(1)$ neighbors and each neighbor can only have $k$ different modules, so we have to check at most $O(k)$ constraints.

This means that checking the modules a slot can have takes $O(k^2)$ time.
Since each change removes at least one module, each slot can change up to $k$ times during the execution of the whole algorithm, and each change leads to $O(1)$ neighbors being checked.
There are $n$ slots which means at most $kn$ changes and $O(kn)$ checks.
Since each check is $O(k^2)$, constraint propagation takes $O(k^3 \cdot n)$ time over the execution of the whole algorithm.

It is easy to see that other steps can are asymptotically faster:
Initialization is done in $O(kn)$ time.
Collapsing $n$ slots takes $O(kn)$ time, assuming selecting a random module takes $O(k)$ time.

\section{Obstacle Generation}\label{sec:analysis-obstacles}

Now that we have generated the attacker paths and terrain, the next step is to generate obstacles.
We know from section~\ref{sec:design-world}, that each tile can have up to one obstacle placed on it.
They block the tiles, so they cannot appear on path tiles.
Which obstacles can appear, and their placement is controlled by the terrain type.
Before we select an algorithm to place them, we should formalize the parameters which influence the obstacle placement.

\subsection{Obstacle Placement Parameters}

In section~\ref{sec:design-world}, we also specified that some obstacles will be more common than others.
In the terrain type specification, we can assign each obstacle a probability of it appearing on each tile.
Some obstacles, for example the \emph{mineral-rich} and \emph{fuel-rich} ones will also have a maximum and minimum count.

Some obstacles will appear more often or less often around other obstacles.
This means that an obstacle's probability to be placed on a given tile will be influenced by the obstacles already placed on surrounding tiles.
For each obstacle type, the terrain type can specify its \emph{affinity} for each other obstacle type.
When trying to place the obstacle on a given tile, its placement probability will be modified for each already placed obstacle by the affinity for that obstacle times the \emph{closeness} to it.
The closeness is some function that decreases with distance, similar to the \emph{crowding penalty} we used in section~\ref{sec:analysis-our-simulated-annealing} when generating paths.

Since each tile can only have one obstacle, the more important obstacles should be placed before others.
For example, we want the resource providing obstacles to be placed first.
So, the obstacle types will be divided into phases, and the first phase will be placed first, then the second, and so on.

In section~\ref{sec:analysis-our-wfc}, we mentioned that each tile will have a surface type from the set of surface types the terrain type allows.
We also want to limit on which surfaces can each obstacle appear.
For example, we don't want trees to appear in water.
This should be all we need to procedurally place obstacles how we want.

\subsection{Obstacle Placement Algorithm}

Placing the obstacles should be fairly straightforward given the parameters we decided on.

The algorithm should place them phase by phase.
For each phase, it will loop through all tiles, and for each tile, it will assign an obstacle to it with the probability that is calculated for that obstacle for that tile.
The probability is 0 for invalid placements, like path tiles, tiles with another obstacle, or tiles with the wrong surface.
When multiple obstacles from the same phase want to be placed on the same tile, we just select one of them at random.

However, we also have a minimum and maximum count for some obstacles.
To adhere to the maximum count, we can just stop placing the obstacle once the maximum count is reached.
This creates a small problem.
If the algorithm went through the tiles in some predefined order, the tiles at the start would have a higher chance of containing obstacles with a count limit than the tiles at the end.
Because once the algorithm reaches the maximum count, it stops placing them.
We can fix this by enumerating the tiles in a random order.

Enforcing the minimum count is also not difficult.
If we finish a phase and there is not enough obstacles of some types, we can do another placement phase, this time only with the obstacle types which didn't reach their minimum yet.
Assuming there is enough tiles with nonzero probability, we can repeat this process until the right amount obstacles is placed.

This is summarized as algorithm~\ref{alg:obstacle-placement}.
Here, a phase is just a set of obstacle types.
Here, the function \textsc{GetPlacementProbability} also checks if the placement would be valid.
If not, it returns 0.

\begin{algorithm}[H]
    \caption{Obstacle placement}
    \label{alg:obstacle-placement}
    \begin{algorithmic}[1]
        \ForEach{phase $p$}
        \While{$p$ is not empty}
        \Statex
        \ForEach{tile $t$ in random order}
        \State $candidates \gets \varnothing$
        \ForEach{obstacle type $o$ in $p$}
        \State $q \gets$ \Call{GetPlacementProbability}{$o, t$}
        \State with probability $q$: $candidates \gets candidates + o$
        \EndFor
        \Statex
        \If{$candidates$ is not empty}
        \State $selected \gets$ random obstacle type from $candidates$
        \State \Call{Place}{$selected, t$}
        \EndIf
        \EndFor
        \Statex
        \ForEach{obstacle type $o$ in $p$}
        \If{number of placed obstacles of type $o \geq o.minimum$}
        \State $p \gets p - o$
        \EndIf
        \EndFor
        \Statex
        \EndWhile
        \EndFor
        \Statex
    \end{algorithmic}
\end{algorithm}

Of course, there are some optimizations we can make.
For example, we don't have to go through all tiles, only those that don't have an obstacle and don't have a path going through them.

\subsection{Generating Obstacle Models}

We can now determine which tiles are blocked by which obstacles.
But by requirement~\ref{RW:obstacle-models}, \enquote{each tile with an obstacle will usually contain a whole procedurally generated cluster of obstacle models}.
How do we generate these models?

For any given obstacle type, we can through all the tiles with that obstacle type and place some number of the corresponding model at random points within the tile.
We can also slightly randomize the rotation and scale of the models to achieve a more natural look.
The terrain type then specifies the number of models per tile and the scale and rotation range.

Just placing the models at random points often creates clusters of intersecting models that don't look nice.
So, we let the terrain type set some minimum distance the models should keep from each other.
If we would place a model at a position that's too close to an already placed model, we don't place it.

However, this still wouldn't feel very natural because the models would create perfect squares.
We would like the boundaries to be more natural too, and even make the models smaller and more spread out near the edges of the boundary.
This is shown in figure~\ref{fig:analysis-obstacles-natural-boundary}.

\begin{center}
    \captionsetup{type=figure}
    \begin{minipage}{.5\textwidth}
        \centering
        \includegraphics[width=0.95\textwidth]{img/inorganic minerals.png}
    \end{minipage}%
    \begin{minipage}{.5\textwidth}
        \centering
        \includegraphics[width=0.95\textwidth]{img/organic minerals.png}
    \end{minipage}
    \caption{Clusters of obstacle models with hard boundaries and with more natural boundaries.}
    \label{fig:analysis-obstacles-natural-boundary}
\end{center}

To achieve this, we can use what the developers of the game \emph{Factorio}~\cite{Factorio} call \emph{noise expressions}.
Earendel has written a great overview of noise expressions on their blog~\cite{NoiseExpressions}.
The main idea is that we specify a function that assigns a value to each point in our world.
For our use-case, the value represents \enquote{how much of an obstacle} is at any given point.
We can then place the obstacle models only where the value is above some threshold, and we scale the models and their spacing by the value too.

This function will be specified in the terrain type for each model.
This means that more different models can be used to represent each obstacle type.
It is created by combining some base functions using arithmetic and other operations.

The most important base function is which tiles have the obstacle we care about and which don't.
We could make a function that returns 1 for points within the tiles with the obstacle and 0 otherwise.
However, this doesn't help us make smooth transitions, because we cannot distinguish points that are just outside a tile with the obstacle from points that are far away.
We would also like to know how far inside the tile with the obstacle is any given point.
So, we need a \emph{signed distance function}, or \emph{SDF}, a function which tells the distance to a boundary, but has a different sign on the outside than the inside.
We can see the SDF of some obstacle tiles in figure~\ref{fig:basic-fns}, along with an SDF for the path tiles, and a function that just returns the height of the terrain at any given point.
For greater convenience, we will also allow to specify the scale of the values of the SDFs, separately for the inside and outside, represented in the figures as \mono{in} and \mono{out}.

\begin{center}
    \captionsetup{type=figure}
    \begin{minipage}{.07\textwidth}
        \centering
        \includegraphics[width=0.95\textwidth]{img/noise expr gradient.pdf}
        \small{\ }
    \end{minipage}%
    \begin{minipage}{.31\textwidth}
        \centering
        \includegraphics[width=0.95\textwidth]{img/obstacle sdf.png}
        \small{\mono{obstacle(in:1, out:-1)}}
    \end{minipage}%
    \begin{minipage}{.31\textwidth}
        \centering
        \includegraphics[width=0.95\textwidth]{img/path sdf.png}
        \small{\mono{path(in:1, out:-1)}}
    \end{minipage}%
    \begin{minipage}{.31\textwidth}
        \centering
        \includegraphics[width=0.95\textwidth]{img/heights.png}
        \small{\mono{height()}}
    \end{minipage}
    \caption{Signed distance functions and height function.}
    \label{fig:basic-fns}
\end{center}

These are very useful building blocks, but they still don't let us create shapes without straight boundaries.
For that we will use a noise function.
However, we don't want a function that just gives us some random value for each point, we need the noise to be smooth and change its value gradually as we move in space.
For this, we can use \emph{Perlin noise}, developed by Perlin and used in their paper \citetitle{PerlinNoise}~\cite{PerlinNoise}.
It is also implemented in the Unity engine, so it is easy to use.
It is deterministic, but we want the noise to be different for each obstacle type.
We can simply sample a different region of the noise by offsetting all our queries with a predetermined random displacement.

In figure~\ref{fig:noise-funcs}, we show what values it produces.
We can scale it up or down, but it is always too smooth or too random.
By adding together more layers of the noise, each with a different scale and amplitude, we can create a result that has both details and large-scale features.

\begin{center}
    \captionsetup{type=figure}
    \begin{minipage}{.07\textwidth}
        \centering
        \includegraphics[width=0.95\textwidth]{img/noise expr gradient.pdf}
        \small{\ \\\ \\\ \\\ }
    \end{minipage}%
    \begin{minipage}{.31\textwidth}
        \centering
        \includegraphics[width=0.95\textwidth]{img/noise2.png}
        \small{\mono{noise(scale:2)\\\ \\\ }}
    \end{minipage}%
    \begin{minipage}{.31\textwidth}
        \centering
        \includegraphics[width=0.95\textwidth]{img/noise3.png}
        \small{\mono{noise(scale:0.5)\\\ \\\ }}
    \end{minipage}%
    \begin{minipage}{.31\textwidth}
        \centering
        \includegraphics[width=0.95\textwidth]{img/fractal noise.png}
        \small{\mono{noise(scale:2) +\\0.5 noise(scale:1) +\\0.25 noise(scale:0.5)}}
    \end{minipage}
    \caption{Examples of Perlin noise.}
    \label{fig:noise-funcs}
\end{center}

In figure~\ref{fig:noise-expr-steps}, we show how we can build up a noise expression that we could use to place obstacle models.
Here, we use some shortcuts for the values it computes in the individual steps, only to save space.
We also use a function called \mono{clamp} which clamps a value between the specified minimum and maximum.

\begin{center}
    \captionsetup{type=figure}
    \begin{minipage}{.07\textwidth}
        \centering
        \includegraphics[width=0.95\textwidth]{img/noise expr gradient.pdf}
        \small{\ \\\ \\\ \\\ }
    \end{minipage}%
    \begin{minipage}{.31\textwidth}
        \centering
        \includegraphics[width=0.95\textwidth]{img/noise expr step1.png}
        \small{\mono{STEP1 =\\clamp(min:-2, max:0.2,\\obstacle(in:1,out:-3))}}
    \end{minipage}%
    \begin{minipage}{.31\textwidth}
        \centering
        \includegraphics[width=0.95\textwidth]{img/noise expr step2.png}
        \small{\mono{STEP2 =\\STEP1 +\\path(in:-2, out:0)}}
    \end{minipage}%
    \begin{minipage}{.31\textwidth}
        \centering
        \includegraphics[width=0.95\textwidth]{img/noise expr step3.png}
        \small{\mono{STEP2 +\\0.8 noise(scale:0.9) +\\0.54 noise(scale:0.45)}}
    \end{minipage}
    \caption{Building up a noise expression step by step.}
    \label{fig:noise-expr-steps}
\end{center}

As a final note, we would like to mention that checking the minimum distance to all other already placed models is very inefficient, because there can be a lot of them, and we need to check the distance of each pair.
However, if we assume that the minimum distance is always less than one tile, we only need to check the models in the current tile and the 8 adjacent tiles.
This even lets us generate models for many tiles in parallel, as long as we don't generate models for tiles that are adjacent at once.

\section{Attacker Wave Generation}\label{sec:analysis-waves}

Now that world generation is done, attacker waves are the last remaining part of battles we want to procedurally generate.
In section~\ref{sec:design-attacker-waves} we have outlined that each wave will be composed of batches, and each batch will contain potentially different attackers spawning on each path.
However, the spacing and count will be shared by the whole batch.
We also mentioned, that the waves need to scale in difficulty, ideally slightly faster than the player could realistically handle.
In section~\ref{sec:analysis-procedural-generation} we also decided that this difficulty will be controlled by the map generator.

Our goal in this section will be to create an algorithm for generating these waves, such that their difficulty somewhat matches the requested difficulty.
We were able to find some quality sources about procedural wave generation in tower defense games, but they generate waves dynamically to adapt to the player's skill, or to find weaknesses in their defenses.
For example~\cite{NeatWaves} \xxx{TODO}.
However, we want the waves to be predetermined only based on the requested difficulty.
And, as stated in section~\ref{sec:design-attacker-waves}, we let the player see them in advance, so the player is the one who adapts, not the waves.

There are also some already existing implementations.
For example, even though the waves in the main game modes of \emph{Bloons TD6} are always the same, there are also game modes with randomized waves.
However, the nature of the algorithm used to generate these waves is not publicly known, and it probably wouldn't be useful us, because the generated waves vary in difficulty a lot.
We were unable to find an example of a tower defense game with procedurally generated waves with a consistent difficulty.

To create a good algorithm that generates waves with a specific difficulty, we need to somehow quantify the difficulty of a wave first.
In the following subsections we aim to find a way to express the difficulty of a wave, that is as simple as possible, but it is close enough for the waves to not feel unfair.
It is important to stress that depending on the player's defenses, some waves will be always harder for them to deal with and others will be easier.
However, if a player is unable to beat some wave, we want them to feel like there were ways to prevent this.
In other words, that the wave was beatable, they just didn't play the best way they could.

As we discussed in section~\ref{sec:analysis-procedural-generation}, the world on which the battle takes place greatly influences the difficulty.
However, we will eliminate this variable and try to quantify the wave difficulty in vacuum.
It will be the responsibility of the map generator to select the right wave difficulty based on the parameters it selected for the world.

Let's simplify our problem to as much as we can to make it easy to find an exact solution.
Then we'll gradually add more complications until we get an approximation of the real problem that is good enough.

\subsection{Model 1: Single Attacker}\label{sec:analysis-waves-single}
For our simplest model, we assume that a wave contains only one attacker with some amount of HP, denoted as $h$, and a speed $s$ in tiles per second.
The attacker has no other qualities or special abilities.
We say the player's defense beats this wave when the attacker is killed before it reaches the Hub.

We also imagine each defensive tower $t$ to always deal some fixed amount of damage $d_t$ per second to the first attacker in its range which covers some region of the path that is $l_t$ long.
This means that the attacker will spend $l_t / s$ seconds in its range, taking $d_t \cdot l_t / s$ damage in total.

A defense $T$ that consists of multiple towers can then deal damage equal to the sum of the individual towers.
This means that the defense can beat the wave if and only if
\begin{equation*}
    \sum_{t \in T} d_t l_t / s \geq h.
\end{equation*}
We will refer to the total damage the towers would deal to an attacker with speed 1 as \emph{buffer} $B$, and
\begin{equation}\label{eqn:B}
    B = \sum_{t \in T} d_t l_t.
\end{equation}
This lets us write the condition more concisely as $B \geq hs$.

From this equation we can see, that the difficulty of this wave is exactly proportional to $hs$.
The defenses that can beat an attacker with 10\,HP and speed~1 are exactly the same as those that can beat an attacker with 5\,HP and speed~2.

This is a great result, but our waves can contain more attackers than one, so we have to generalize.
Next, we will take a look at a case with an infinite amount of attackers.

\subsection{Model 2: Infinite Waves}
For this model, everything is the same as in the previous model, but each wave consists of infinitely many attackers of one attacker type.
We will denote the spacing (or gap) between the attackers as $g$, measured in seconds.
This means that the physical distance between the attackers will be $sg$ tiles.
Here, we say the player's defense beats this wave when no attacker ever reaches the Hub.

The towers still deal damage only to the first attacker.
Imagine the first attacker is killed after it has travelled $p$ tiles.
Assuming at least $g$ seconds have passed, this means that the second attacker has already traveled $p - sg$ tiles, so the defenses have less time to kill it than they had for the first attacker.
If the towers progressively kill the attackers later and later, eventually, one of them will reach the Hub.
Intuitively, the towers need to be able to kill an attacker every $g$ seconds to beat the wave.

When each attacker spends at least $g$ seconds within the range of each tower, then each tower $t$ deals in total $d_t g$ damage to each attacker.
However, when the spacing is larger, some towers won't be able to deal damage to each attacker for $g$ seconds, but only $l_t / s$ as we determined in the previous model.
So, each tower can only deal $d_t$ damage per second for $\min(l_t / s, g)$ seconds, so the towers will deal in total
\begin{equation*}
    \sum_{t \in T} d_t \cdot \min(l_t / s, g)
\end{equation*}
damage to each attacker.

It is more useful to think about the damage per second, so let $R$ be the total damage per second the player's defenses can deal to the attackers, or the \emph{damage rate}.
One attacker spawns each $g$ seconds, so when we divide the previous equation by $g$, we get that
\begin{equation}\label{eqn:R}
    R = \sum_{t \in T} d_t \cdot \min(l_t / (s g), 1).
\end{equation}
We see that $R$ is at most $\sum_{t \in T} d_t$, and it is equal to it only if $l_t / (sg) \geq 1$ for each tower $t$.
$R$ is also at most $\sum_{t \in T} d_t \cdot l_t / (s g)$, and it is equal to it in the other cases, when $l_t / (sg) \leq 1$.
By equation~\ref{eqn:B}, $\sum_{t \in T} d_t \cdot l_t / (s g) = B/(s g)$, so we know that
\begin{equation}\label{eqn:RB}
    R \leq \frac{B}{s g}
\end{equation}
This is an important fact that will be useful later.

Since one attacker spawns every $g$ seconds, the towers can deal at most $Rg$ damage to each attacker.
So, the player will beat the game if and only if $Rg \geq h$.
Sometimes, $R$ does not depend only on the player's defenses, but also on the attacker speed $s$ and spacing $g$.
However, this should be very rare, because the maximum spacing we will use is $g=2$ seconds, and no attacker will be faster than $s=4$ tiles per second, which is still extremely fast compared to most attackers.
This means that every tower has to have $l_t \geq 8$ for $g$ and $s$ to never influence $R$, which is easily achievable with most tower types.
For now, we can think of $R$ as being a constant determined by the player's defenses.

\subsection{Model 3: Finite Waves}\label{sec:analysis-waves-finite}
In this model, we add another parameter to our wave.
The wave is once again composed of attackers with $h$ HP and speed $s$, coming with a spacing of $g$ seconds, but this time, there is exactly $n$ of them.
How do we judge the wave difficulty now?

The best way to think about this is that the player's towers need to deal $nh$ damage in total.
From \hyperref[sec:analysis-waves-single]{model~1} we know that if the whole wave was a single attacker, the player's defenses would deal $B/s$ damage in total.
So, they would defeat the wave if and only if $B/s \geq nh$.

The towers still target only the first attacker, so they will kill it first.
Then, they can deal with the second attacker, but the second attacker is $g$ seconds behind the first, so they have $g$ more seconds to deal with it.
This is also true for each other attacker, so the towers effectively get $g$ seconds of firing for free for each attacker beyond the first.
\begin{equation*}
    B/s + (n-1) R g \geq nh.
\end{equation*}
When we put all wave-dependent terms on the right and rearrange, we get that the player beats the wave if and only if
\begin{equation}\label{eqn:beat-finite-wave}
    B \geq s(nh - (n - 1)Rg).
\end{equation}

We cannot quantify the difficulty of the wave with one number anymore.
For example, there exists a defense $T_1$ which beats the wave, and another defense $T_2$ which also beats it, despite having lower $B$, because it has greater $R$.
So, we have to accept that each defense has two characteristic values.

Now we can finally explain why we call $B$ the \emph{buffer}.
In the time it takes for the wave to spawn, the player's defenses can deal $Rg$ damage to each attacker.
Then $B$ can be thought of as an additional buffer of firepower they have to clean up the rest.

In figure~\ref{fig:model3} we show the set of defenses that can beat a particular wave, and we show how it changes when the wave's parameters change.
The blue area represents the defenses which can beat the wave, and the orange area represents defenses that can't exist because they would violate inequality~\ref{eqn:RB}.
We also highlight two points in each chart, each of these points represents one example defense.
$T_1$ consists of one tower with $d_t=5$ and $l_t=12$.
$T_2$ consists of one tower with $d_t=10$ and $l_t=1.5$ which is an unusually small path coverage, to showcase what happens when $l_t/(sg) < 1$ as shown in figures~\ref{fig:model3-s2} and~\ref{fig:model3-g2}.

\begin{center}
    \captionsetup{type=figure}
    \begin{minipage}{.33\textwidth}
        \centering
        \includegraphics[width=0.95\linewidth]{img/model3 base.pdf}
        \subcaption{$h=10, s=1,$\\$ g=1, n=4$}
    \end{minipage}%
    \begin{minipage}{.33\textwidth}
        \centering
        \includegraphics[width=0.95\linewidth]{img/model3 h20.pdf}
        \subcaption{$\bm{h=20}, s=1,$\\$ g=1, n=4$}
    \end{minipage}%
    \begin{minipage}{.33\textwidth}
        \centering
        \includegraphics[width=0.95\linewidth]{img/model3 s2.pdf}
        \subcaption{$h=10, \bm{s=2},$\\$ g=1, n=4$}
        \label{fig:model3-s2}
    \end{minipage}\\
    \begin{minipage}{.33\textwidth}
        \centering
        \includegraphics[width=0.95\linewidth]{img/model3 g0.5.pdf}
        \subcaption{$h=10, s=1,$\\$ \bm{g=0.5}, n=4$}
    \end{minipage}%
    \begin{minipage}{.33\textwidth}
        \centering
        \includegraphics[width=0.95\linewidth]{img/model3 g2.pdf}
        \subcaption{$h=10, s=1,$\\$ \bm{g=2}, n=4$}
        \label{fig:model3-g2}
    \end{minipage}\\
    \begin{minipage}{.33\textwidth}
        \centering
        \includegraphics[width=0.95\linewidth]{img/model3 n1.pdf}
        \subcaption{$h=10, s=1,$\\$ g=1, \bm{n=1}$}
    \end{minipage}%
    \begin{minipage}{.33\textwidth}
        \centering
        \includegraphics[width=0.95\linewidth]{img/model3 n12.pdf}
        \subcaption{$h=10, s=1,$\\$ g=1, \bm{n=12}$}
    \end{minipage}%
    \caption{Which defenses can beat various attacker waves, according to model 3.}
    \label{fig:model3}
\end{center}

\subsection{Model 4: Damage in an Area}
Many towers will be able to deal damage to all attackers in some area.
These towers are much more effective against large groups of attackers, especially when they are close together.
We can model these towers similarly to what we have done so far, but we will add one more parameter, the damage range $r_t$.
Now, each tower $t$ deals $d_t$ damage per second to the first attacker, but also all the attackers at most $r_t$ tiles behind it.
This still makes all calculations much more difficult, so we will choose to ignore many edge cases.

Intuitively, for the first attacker of every wave, nothing changes.
To kill it, the condition $B/s \geq h$ still holds.
Killing the second attacker is easier as it has already been damaged by collateral damage.
The attackers spawn $g$ seconds apart, so each can travel $sg$ tiles before the next one spawns, making the gaps between them $sg$ tiles long.
So, the second attacker has been receiving collateral damage from all towers $t$ with $r_t \geq sg$.
But how much damage is that?

To simplify our calculations, we will introduce some new variables $R_k$.
$R_1$ is the damage rate of towers which hit one extra attacker with collateral damage, $R_2$ for towers which deal damage to two extra attackers, and so on.
Formally, $\forall k \in \mathbb{N}$ let $R_k$ be the damage rate (see equation~\ref{eqn:R}) of towers $t$ with $r_t \geq ksg$.

Killing the first attacker will take $t_1 = h/R$ seconds as usual, and in the time, the second attacker will take $t_1 R_1$ collateral damage.
In general, the $k$th attacker will take $t_1 R_{k-1}$ collateral damage from towers shooting at the first attacker.
Let $t_k$ be the time it takes for the $k$th attacker to be killed by towers continuously shooting at it.
It is equal to the remaining health the attacker will have after the ones before it have been killed, divided by $R$ or specifically
\begin{equation}\label{eqn:time-to-kill}
    t_k = \frac{1}{R}\left(h - \sum_{i=1}^{k-1} t_i R_{k-i} \right).
\end{equation}

This is still very complicated, and we also need too many variables to specify the player's defenses.
However, this can be simplified with the right assumptions.
The game should force the player use towers that deal damage in an area, in addition to those with a single target.
So, we can just assume they have them when generating the waves, and make it the player's responsibility to adapt to the waves by building the right towers.

The greater the tower's damage range $r_t$, the less damage it should deal and the less often it should appear.
Let's assume that in a balanced defense, the towers' damage rate decreases exponentially with increasing $r_t$.
Formally, for each $x \in \R_0^+$ we create a subset of towers $Tx = {t \in T \vert r_t \geq x}$.
We say that a defense is $\lambda$-balanced for some $\lambda \in (0,1)$ when $\forall x \in \R_0^+$, the damage rate of towers in $Tx$ is equal to $\lambda^x R$.
We will select the right $\lambda$ for this exponential decrease based on playtesting.

Now we can precisely determine all $R_k$ for a given wave.
From the definition, $R_k$ is the damage rate of towers with $r_t \geq ksg$, so $R_k = R \cdot \lambda^{ksg}$.
We can substitute this into equation~\ref{eqn:time-to-kill} to get
\begin{equation*}
    t_k = \frac{1}{R}\left(h - \sum_{i=1}^{k-1} t_i \cdot R \cdot \lambda^{(k-i)sg}\right).
\end{equation*}

For $t_1$, the summation is empty, so $t_1$ is still equal to $h/R$.
For $k > 1$ we can simplify further:
\begin{align*}
    t_k & = \frac{1}{R}\left(h - \sum_{i=1}^{k-1} t_i \cdot R \cdot \lambda^{(k-i)sg} \right)              \\
        & = \frac{h}{R} - \sum_{i=1}^{k-1} t_i \cdot \lambda^{(k-i)sg}                                     \\
        & = \frac{h}{R} - \sum_{i=1}^{k-1} t_i (\lambda^{sg})^{(k-i)}                                      \\
        & = \frac{h}{R} - t_1 (\lambda^{sg})^{(k-1)} - \sum_{i=2}^{k-1} t_i (\lambda^{sg})^{(k-i)}.        \\
    \intertext{Now we substitute for $t_1$,}
        & = \frac{h}{R} - \frac{h}{R} (\lambda^{sg})^{(k-1)} - \sum_{i=2}^{k-1} t_i (\lambda^{sg})^{(k-i)} \\
        & = \frac{h}{R} (1 - (\lambda^{sg})^{(k-1)}) - \sum_{i=2}^{k-1} t_i (\lambda^{sg})^{(k-i)}.
\end{align*}
Now we know that $t_2 = (h/R)(1 - \lambda^{sg})$, since the summation on the right is empty for $k=2$.

We can continue simplifying for $k > 2$
\begin{align*}
    t_k & = \frac{h}{R} (1 - (\lambda^{sg})^{(k-1)}) - \sum_{i=2}^{k-1} t_i (\lambda^{sg})^{(k-i)}                                                         \\
        & = \frac{h}{R} (1 - (\lambda^{sg})^{(k-1)}) - t_2 (\lambda^{sg})^{(k-2)} - \sum_{i=3}^{k-1} t_i (\lambda^{sg})^{(k-i)}                            \\
        & = \frac{h}{R} (1 - (\lambda^{sg})^{(k-1)}) - \frac{h}{R} (1 - \lambda^{sg}) (\lambda^{sg})^{(k-2)} - \sum_{i=3}^{k-1} t_i (\lambda^{sg})^{(k-i)} \\
        & = \frac{h}{R} (1 - (\lambda^{sg})^{(k-1)} - (1 - \lambda^{sg}) (\lambda^{sg})^{(k-2)}) - \sum_{i=3}^{k-1} t_i (\lambda^{sg})^{(k-i)}             \\
        & = \frac{h}{R} (1 - (\lambda^{sg})^{(k-1)} - (\lambda^{sg})^{(k-2)} + (\lambda^{sg})^{(k-1)}) - \sum_{i=3}^{k-1} t_i (\lambda^{sg})^{(k-i)}       \\
        & = \frac{h}{R} (1 - (\lambda^{sg})^{(k-2)}) - \sum_{i=3}^{k-1} t_i (\lambda^{sg})^{(k-i)}.
\end{align*}
This means that $t_3$ is also $(h/R)(1 - \lambda^{sg})$.
We could repeat this process and use induction to prove that for all $k > 1$, $t_k = (h/R)(1 - \lambda^{sg})$.

Now we can finally construct an updated condition for beating this wave.
By definition of $t_k$, we know that each attacker will have $Rt_k$ HP when all attackers before it die.
So, the player's defenses needs to deal in total $\sum_{k=1}^{n} Rt_k$ damage to all the attackers while they are the first attacker alive, instead of $hs$.
Otherwise, the derivation is the same as for \hyperref[sec:analysis-waves-finite]{model~3}, so the player will beat a wave if and only if
\begin{equation*}
    B/s + (n-1)Rg \geq \sum_{k=1}^{n} Rt_k.
\end{equation*}
Then we substitute for $t_k$:
\begin{equation*}
    B/s + (n-1)Rg \geq nh - (n-1)h\lambda^{sg}.
\end{equation*}
If we put all wave-dependent terms on the right again, we get
\begin{equation}\label{eqn:beat-wave-with-aoe}
    B \geq s(nh - (n-1)(Rg + h\lambda^{sg})).
\end{equation}
We can see this condition is very similar to the one for model 3 (inequality~\ref{eqn:beat-finite-wave}).

\subsection{Model 5: Multiple Batches}
So far we have considered only waves with one attacker type.
In section~\ref{sec:design-attacker-waves} we mentioned that waves can consist of up to three batches.
Each batch contains some number of attackers of one attacker type which are spaced by some spacing.
We can specify a set of wave parameters for each batch $b_k$ instead of having one for the wave as a whole.
These parameters have a subscript which denotes which batch they correspond to, for example the first batch ($b_1$) contains attackers with $h_1$\,HP and speed $s_1$.

To determine which defenses will beat a wave with $N$ batches, we could extend the condition for model 4 (inequality~\ref{eqn:beat-wave-with-aoe}).
The defenses simple have to beat all the batches one by one, but they still have the same buffer $B$.
This gives us
\begin{equation*}
    B \geq \sum_{k=1}^{N} s_k (n_k h_k - (n_k - 1)(R g_k + h_k \lambda^{s_k g_k})).
\end{equation*}

However, there is more we need to consider.
There is a pretty big issue which manifests for example, when the first batch spawns small attackers with large spacing, so the defenses can kill each of them before then next one spawns, and for the second batch this is no longer true.
The current formula essentially allows dealing damage in advance to attackers that haven't spawned yet, because the therm $R g_k + h_k \lambda^{s_k g_k}$ is not limited by the total health of the attacker.
To fix this, we need to introduce this limit, so we get
\begin{equation*}
    B \geq \sum_{k=1}^{N} s_k (n_k h_k - (n_k - 1)\min(R g_k + h_k \lambda^{s_k g_k}, h_k)).
\end{equation*}
This wasn't a problem before, because this only happened for waves which the defenses beat anyway, so we didn't mention it.
It is a problem now, because beating one batch doesn't guarantee beating all of them.

We specified that the spacing between batches will be 1 second, but the previous condition acts like the next batch begins right when the previous one ends.
An updated condition could look like this:
\begin{equation*}
    B \geq \sum_{k=1}^{N} s_k (n_k h_k - (n_k - 1)\min(R g_k + h_k \lambda^{s_k g_k}, h_k)) - \sum_{k=2}^{N} s_k \cdot \min(R + h_k \lambda^{s_k}, h_k).
\end{equation*}
However, the collateral damage calculations are all wrong.
We never investigated what happens with an uneven attacker spacing, but we don't even know what's the spacing going to be like.
We know how far each attacker spawns behind the attacker before it, but attackers from different batches can have different speeds, so the spacing between them changes, and they can even overtake each other.

There really isn't a way to capture this behavior in our model without making it much more complicated.
So, we will ignore this problem, and hope that the waves we generate don't deviate in difficulty too much from our estimate.
If this ends up being a problem, we can adjust the wave generation algorithm to only produce waves that aren't problematic.
The only thing we'll change is that we'll ignore collateral damage across batches, giving us the following condition:
\begin{equation}
    B \geq \sum_{k=1}^{N} s_k (n_k h_k - (n_k - 1)\min(R g_k + h_k \lambda^{s_k g_k}, h_k)) - \sum_{k=2}^{N} s_k \cdot \min(R, h_k).
\end{equation}

\subsection{Model 6: Multiple Paths}
The levels in our game can have multiple paths, and we can even spawn different attackers on each path.
Since all paths in a single level will have similar lengths, we can treat them all the same.
To start, we'll assume that the paths don't interact in any way and that each tower can only shoot at attackers on one path.
This means that each path $p_k$ will have its own buffer $B_k$ and damage rate $R_k$.
The player's defenses then beat a wave if they beat it on each path.

However, when generating a wave, we'll generate it to have the difficulty determined by the map generator.
We want the difficulty of each path to vary between waves, but the overall difficulty to smoothly increase.
It would be weird for the map generator to dictate the difficulty of each path separately, the wave generator should take care of that.
By limiting what the wave generator can do, we don't have to modify our calculations to consider the relationships between different paths or other waves.
So, we define the overall difficulty using one buffer $B$ and damage rate $R$ and for each wave, the wave generator will divide them between the paths.
Since towers provide both $B$ and $R$ at once, it would be weird to expect some path $p_k$ to have high $B_k$ but low $R_k$.
So the wave generator should always divide them in the same proportions.

Since the towers a player builds stay on the same tile for the entire battle, we can't expect the player to have all their firepower concentrated on one path and then suddenly on a different path.
So, the wave generator should accumulate the $B_k$ and $R_k$ of each path $p_k$.
For each wave, it will determine the new $B$ and $R$ the wave should have over the previous wave, and randomly distribute only that.

We can expect the player to place some tower such that their range covers more than one path.
This breaks our assumption that the paths are independent.
To encourage the player to do this, we will designate a fraction of the total buffer as \emph{global}.
This portion of the buffer will not be assigned to any path, and it can be spent on different paths in every wave.
How much of the buffer will be global will have to be determined by playtesting.

\subsection{Model 7: Abilities}
So far, we've only considered attackers that have no abilities, towers with no special abilities, and we ignored the abilities the player can use (see section~\ref{sec:design-abilities}).
In this section, we will incorporate these into our wave difficulty estimate.

Usable abilities usually provide one-time damage to the attackers, so they effectively contribute to the buffer of the player's defenses.
Similarly, special abilities of towers or other buildings which have some effect on the attackers, usually just make the defense more effective, thus increasing its buffer or damage rate.
These should all be balanced based on playtesting, so they aren't too weak or too strong.
Thus, they don't need any special treatment in our calculations.

On the other hand, attacker abilities is something the wave generator should consider.
We don't want it to spawn lots of attackers which have very strong abilities just because of their low HP and slow speed.
These abilities can vary widely in their effect and can interact in unpredictable ways.
However, we hope it's enough to assign each attacker a value which will be used in all the calculations we did so far instead of their HP.
For example, an attacker with no special abilities and 10\,HP will still have a value of 10.
If it had an ability that makes it take 50\% less physical damage, its value might be about 13.
Also, the damage rate of a defense (see equation~\ref{eqn:R}) is also influenced by the attacker speed, but we treated it as a constant the whole time.
We can increase the value of very fast attackers to offset this, treating super-speed as a kind of special ability.
The important thing is that this value can be tweaked based on playtesting.

This way of quantifying the wave difficulty should be good enough to let us produce waves that vary widely in their feel, but are consistent in their difficulty, so they don't feel unfair to the player.

\subsection{Generating Waves}

- yay

\section{Simulation}

- use fixed updates for game logic

- why?

- 20Hz = fixed time step 0.05s

- options to speed up or possibly pause - changing fixed update rate - not yet implemented

\section{Visuals and Interpolation}

- interpolate positions and visuals on Update

- many visuals are game-speed agnostic     - TODO: use unscaledDeltaTime

- I thought about some custom mini-framework for this, but many of the simulated variables the visuals are based on should be handled on case-by-case basis

\section{Attacker Targeting}

- Towers use it to acquire targets

- handles which Attackers are in range and which one is chosen as the current target

- can require line of sight to the enemy

- different targeting types

- rotation

- heights

- possibly ensure a trajectory

- preferred target (configurable)

- composite colliders

\section{Range Visualization}

- IMAGES!!

- Draw the range on the terrain mesh

- Draw on which parts of paths will Attackers be targeted

- green - all sizes

- yellow - only large

- Terrain shader uses compressed texture format instead of raw texture

- Options:

- quadrant compression format, 2bytes per node

- less CPU time, because the data is already in this format

- up to 48KiB per frame

- more GPU time

- 256x256 texture, 1byte per pixel

- more CPU time

- 64KiB per frame

- fast on GPU

- only 1 channel - cannot interpolate

- mipmaps -> one additional state

- less CPU time

- 33\% more data

- more pixels per byte

- possible future optimization

- less data

- more difficult indexing and stuff both on CPU and GPU

- interpolation could work with more than one channel and without mipmaps

\section{Game Commands}

- we want various components to modify how other components function

- examples

- also react to events as a bonus

\section{Blueprints}

- separation of stats from behavior

- why are they implemented this way

\subsection{Attacker Stats}

- blueprints for attackers

\subsection{Dynamic Descriptions}

- explain what things do and their stats

- attackers and blueprints

- dynamically reflect the changes made by other components

\section{Random Number Generators}\label{sec:analysis-rng}

Randomized algorithms, like the ones we will use for procedural generation, depend on a \emph{random number generator} as their source of randomness.
A \textbf{random number generator} (or \emph{RNG}) produces a sequence of numbers that looks random and is unpredictable.
They are well explained in \citetitle{johnston2018random}~\cite{johnston2018random} by David Johnston.
Some RNGs use specialized hardware to generate truly random data using an external source of entropy, these are called \emph{true random number generators}.
However, we want a \emph{deterministic RNG}, also known as a \emph{pseudorandom number generator} (\emph{PRNG}).
These produce the random data using a completely deterministic algorithm, but unless we know the current internal state of the generator, the outputs still can't be predicted.
The initial state of a PRNG is called the \emph{seed}, and a generator will always generate the same sequence of outputs when \emph{seeded} with the same value.

Each query advances the generator's state, so the value a deterministic random number generator returns depends on the number of previous requests.
If we used one generator for generating everything, the outcomes of different systems would depend on the order they were generated in.
For example, when a player triggers some effect that uses randomness \emph{before} generating a level, the level would be different than if the player triggered the randomized effect \emph{after} the level was generated.
To remedy this, we will utilize a simple trick we call \emph{seed branching} all throughout the procedural generation.
Whenever we want more systems to be independent of each other, we create a new RNG instance for each system, and we seed them with each with a seed generated from the old RNG in advance.
For example, we will have a master RNG seeded with the seed of the run, from which we will generate the seeds for the map generator, reward systems, etc.
The map generator itself will generate the run map and then assign a new seed to each of the levels planned on the map, and so on.

We can determine what properties are required of the RNG we are going to use from our use-case.
First, obviously, the numbers generated by the generator should be random enough.
However, the RNG doesn't have to be cryptographically secure or pass strict statistical tests, since we aren't going to use them for cryptography or scientific simulations.
Since we will create many instances of the RNG, it should be lightweight and fast to initialize.
Some of them, for example the ones used by the reward system, will persist throughout the whole run, so we need an easy way to save the RNG's current state.
So, what options do we have?

Since we are using Unity, the first RNG that comes to mind is Unity class \mono{Random}~\cite{UnityRandom}.
It is designed to be easy to use, but it is very limited~--- for example, we have access to only one instance of the class and the same instance is used for other systems within the game engine.
This is a dealbreaker for us, because we want to create more instances, and we want to have complete control over them to ensure determinism.

Another option that's on-hand is .NET \mono{System.Random}~\cite{SystemRandom}.
According to the documentation, instantiating a random number generator is fairly expensive.
Furthermore, there are no methods to read and set the internal state of the generator.
This becomes a problem when we want to save the state of an instance to restore it later, for example when loading a save file.
We would have to serialize and deserialize the instance, which isn't a big problem, but it feels inelegant and inefficient.

Instead, we chose to go with a more straight-forward option~--- making our own RNG.
This way, we can make the generator have all the features we need.
There are many algorithms a PRNG can use.
Johnston describes in their book~\cite{johnston2018random} some most commonly used non-cryptographic PRNGs, namely:
\begin{itemize}
    \item Linear congruential generators (LCG),
    \item Multiply with carry (MWC),
    \item XORSHIFT,
    \item Permuted congruential generators (PCG).
\end{itemize}
All of these are random enough for our use-case, provided we use the right parameter values, so we chose an LCG, because it seemed the most simple to implement.
In the article \citetitle{LCGTables}~\cite{LCGTables}, the author explains the statistical tests they used to measure the randomness of the LCGs and tabulates the best-performing parameter combinations.
From there we took the parameters for our LCG implementation.